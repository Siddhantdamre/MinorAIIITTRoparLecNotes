{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ffXG9GDiAwzC",
        "outputId": "c4aeaf2a-c84b-47c6-a0dc-d3b3ce42baac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.12/dist-packages (2.19.0)\n",
            "Collecting tensorflow-model-optimization\n",
            "  Downloading tensorflow_model_optimization-0.8.0-py2.py3-none-any.whl.metadata (904 bytes)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.9.23)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (5.29.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.32.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.2.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (4.15.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.0.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.76.0)\n",
            "Requirement already satisfied: tensorboard~=2.19.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.19.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.10.0)\n",
            "Requirement already satisfied: numpy<2.2.0,>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.0.2)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.15.1)\n",
            "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.5.4)\n",
            "Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow-model-optimization) (0.1.9)\n",
            "Collecting numpy<2.2.0,>=1.26.0 (from tensorflow)\n",
            "  Downloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: attrs>=18.2.0 in /usr/local/lib/python3.12/dist-packages (from dm-tree~=0.1.1->tensorflow-model-optimization) (25.4.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (0.18.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.11.12)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
            "Downloading tensorflow_model_optimization-0.8.0-py2.py3-none-any.whl (242 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.5/242.5 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.0/18.0 MB\u001b[0m \u001b[31m52.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy, tensorflow-model-optimization\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "jax 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "pytensor 2.35.1 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "jaxlib 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "shap 0.50.0 requires numpy>=2, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.26.4 tensorflow-model-optimization-0.8.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              },
              "id": "b7f228ae789644cab5c2f2b9dcd2c42d"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "pip install tensorflow tensorflow-model-optimization"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "_9L3AeHGnBMs"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "lgnLs2xBNBXY"
      },
      "outputs": [],
      "source": [
        "!pip uninstall -y numpy tensorflow tensorflow_model_optimization\n",
        "!pip install numpy tensorflow tensorflow_model_optimization --upgrade --force-reinstall"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C6Dt1_KmMDXq"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_model_optimization as tfmot\n",
        "import numpy as np\n",
        "import os\n",
        "import tempfile\n",
        "\n",
        "# ----------------------------------------\n",
        "# 1. Load and preprocess MNIST\n",
        "# ----------------------------------------\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "x_train = x_train[..., tf.newaxis] / 255.0\n",
        "x_test = x_test[..., tf.newaxis] / 255.0\n",
        "\n",
        "# ----------------------------------------\n",
        "# 2. Define LeNet-5\n",
        "# ----------------------------------------\n",
        "\n",
        "def create_lenet():\n",
        "    model = tf.keras.Sequential([\n",
        "        tf.keras.layers.Conv2D(6, kernel_size=5, activation='relu', input_shape=(28,28,1), padding='same'), #layer 1\n",
        "       tf.keras.layers.AveragePooling2D(pool_size=(2, 2)),                                                  # Layer 2\n",
        "\n",
        "        tf.keras.layers.Conv2D(filters=16, kernel_size=(5, 5), activation='relu'),                           # Layer 3\n",
        "        tf.keras.layers.AveragePooling2D(pool_size=(2, 2)),                                                  # Layer 4\n",
        "\n",
        "        tf.keras.layers.Conv2D(filters=120, kernel_size=(5, 5), activation='relu'),                          # Layer 5\n",
        "\n",
        "        tf.keras.layers.Flatten(),\n",
        "        tf.keras.layers.Dense(units=84, activation='relu'),                                                  # Layer 6\n",
        "        tf.keras.layers.Dense(units=10, activation='softmax')\n",
        "    ])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "bW2pUmvrMabu",
        "outputId": "084aa06e-7685-44e0-9828-a4ce14f81ba0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'create_lenet' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-759806500.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# ----------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_lenet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sparse_categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'create_lenet' is not defined"
          ]
        }
      ],
      "source": [
        "# ----------------------------------------\n",
        "# 3. Train Baseline Model\n",
        "# ----------------------------------------\n",
        "\n",
        "model = create_lenet()\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.fit(x_train, y_train, epochs=3, validation_split=0.1, verbose=2)\n",
        "baseline_loss, baseline_acc = model.evaluate(x_test, y_test, verbose=0)\n",
        "\n",
        "# Save and check baseline model size\n",
        "_, baseline_model_path = tempfile.mkstemp('.h5')\n",
        "model.save(baseline_model_path)\n",
        "baseline_size = os.path.getsize(baseline_model_path) / 1e6  # in MB\n",
        "\n",
        "print(f\"Baseline accuracy: {baseline_acc:.4f}, loss: {baseline_loss:.4f}, size: {baseline_size:.2f} MB\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mYVWtALrNw9_"
      },
      "outputs": [],
      "source": [
        "path = \"baseline_lenet5.h5\"\n",
        "model.save(path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "jj9B_v_pMgwd"
      },
      "outputs": [],
      "source": [
        "# ----------------------------------------\n",
        "# 4. Apply Structured Pruning (filter pruning)\n",
        "# ----------------------------------------\n",
        "\n",
        "# Prune only Conv2D and Dense layers with 50% sparsity\n",
        "prune_low_magnitude = tfmot.sparsity.keras.prune_low_magnitude\n",
        "\n",
        "pruning_params = {\n",
        "    'pruning_schedule': tfmot.sparsity.keras.ConstantSparsity(\n",
        "        target_sparsity=0.5, begin_step=0, frequency=100\n",
        "    ),\n",
        "    # 'block_size': (1, 1),\n",
        "    # 'block_pooling_type': 'AVG',\n",
        "}\n",
        "\n",
        "def apply_structured_pruning(model):\n",
        "    def prune_layer(layer):\n",
        "        if isinstance(layer, tf.keras.layers.Conv2D) or isinstance(layer, tf.keras.layers.Dense):\n",
        "            return prune_low_magnitude(layer, **pruning_params)\n",
        "        return layer\n",
        "\n",
        "    pruned_model = tf.keras.models.clone_model(\n",
        "        model,\n",
        "        clone_function=prune_layer,\n",
        "    )\n",
        "    return pruned_model\n",
        "\n",
        "pruned_model = apply_structured_pruning(model)\n",
        "\n",
        "# Compile and retrain the pruned model\n",
        "pruned_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Callback to update pruning during training\n",
        "callbacks = [tfmot.sparsity.keras.UpdatePruningStep()]\n",
        "\n",
        "pruned_model.fit(x_train, y_train, epochs=3, validation_split=0.1, callbacks=callbacks, verbose=2)\n",
        "pruned_loss, pruned_acc = pruned_model.evaluate(x_test, y_test, verbose=0)\n",
        "\n",
        "# ----------------------------------------\n",
        "# 5. Strip pruning wrappers & check size\n",
        "# ----------------------------------------\n",
        "\n",
        "model_for_export = tfmot.sparsity.keras.strip_pruning(pruned_model)\n",
        "\n",
        "_, pruned_model_path = tempfile.mkstemp('.h5')\n",
        "model_for_export.save(pruned_model_path)\n",
        "pruned_size = os.path.getsize(pruned_model_path) / 1e6  # in MB\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ryUK2sdcO7DJ"
      },
      "outputs": [],
      "source": [
        "path_pruned = \"pruned-lenet5.h5\"\n",
        "model_for_export.save(path_pruned)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wp4lxwSsMiKC"
      },
      "outputs": [],
      "source": [
        "# ----------------------------------------\n",
        "# 6. Print Comparison\n",
        "# ---------------------\n",
        "# -------------------\n",
        "\n",
        "print(\"\\n Results Comparison:\")\n",
        "print(f\"Baseline accuracy: {baseline_acc:.4f}, loss: {baseline_loss:.4f}, size: {baseline_size:.2f} MB\")\n",
        "print(f\"Pruned   accuracy: {pruned_acc:.4f}, loss: {pruned_loss:.4f}, size: {pruned_size:.2f} MB\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wkklrpf9RJbr"
      },
      "outputs": [],
      "source": [
        "# --------------------------\n",
        "# Post Training Quantization\n",
        "# --------------------------\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import tempfile\n",
        "import os\n",
        "\n",
        "# Evaluate float model\n",
        "float_loss, float_acc = model.evaluate(x_test, y_test, verbose=0)\n",
        "\n",
        "# Save float model\n",
        "_, float_model_file = tempfile.mkstemp('.h5')\n",
        "model.save(float_model_file)\n",
        "float_model_size = os.path.getsize(float_model_file) / 1e6  # MB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "1Yc6JMbRRoMz"
      },
      "outputs": [],
      "source": [
        "\n",
        "# ----------------------------\n",
        "# 4. Convert to TFLite (PTQ)\n",
        "# ----------------------------\n",
        "\n",
        "# Provide a representative dataset for calibration\n",
        "def representative_data_gen():\n",
        "    for i in range(100):\n",
        "        yield [x_train[i:i+1].astype(np.float32)]\n",
        "\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "converter.representative_dataset = representative_data_gen\n",
        "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
        "converter.inference_input_type = tf.uint8\n",
        "converter.inference_output_type = tf.uint8\n",
        "\n",
        "quantized_tflite_model = converter.convert()\n",
        "\n",
        "# Save quantized model\n",
        "quant_model_path = os.path.join(tempfile.gettempdir(), \"lenet_int8.tflite\")\n",
        "with open(quant_model_path, 'wb') as f:\n",
        "    f.write(quantized_tflite_model)\n",
        "\n",
        "quant_model_size = os.path.getsize(quant_model_path) / 1e6  # MB\n",
        "\n",
        "# ----------------------------\n",
        "# 5. Evaluate TFLite Model\n",
        "# ----------------------------\n",
        "\n",
        "# Load interpreter\n",
        "interpreter = tf.lite.Interpreter(model_path=quant_model_path)\n",
        "interpreter.allocate_tensors()\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()\n",
        "\n",
        "# Run inference\n",
        "correct = 0\n",
        "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy()\n",
        "\n",
        "preds = []\n",
        "for i in range(len(x_test)):\n",
        "    x = x_test[i:i+1]\n",
        "    label = y_test[i:i+1]\n",
        "\n",
        "    # Quantize input\n",
        "    input_scale, input_zero_point = input_details[0]['quantization']\n",
        "    x_q = (x / input_scale + input_zero_point).astype(np.uint8)\n",
        "\n",
        "    interpreter.set_tensor(input_details[0]['index'], x_q)\n",
        "    interpreter.invoke()\n",
        "    output = interpreter.get_tensor(output_details[0]['index'])\n",
        "\n",
        "    # Dequantize output\n",
        "    pred = np.argmax(output)\n",
        "    preds.append(output)\n",
        "\n",
        "    if pred == label:\n",
        "        correct += 1\n",
        "\n",
        "quant_acc = correct / len(x_test)\n",
        "\n",
        "# Compute quantized loss\n",
        "preds = tf.constant(np.vstack(preds), dtype=tf.float32)\n",
        "quant_loss = loss_fn(y_test, preds).numpy()\n",
        "\n",
        "# ----------------------------\n",
        "# 6. Print Results\n",
        "# ----------------------------\n",
        "print(\"\\nComparison:\")\n",
        "print(f\"Float   - Accuracy: {float_acc:.4f}, Loss: {float_loss:.4f}, Size: {float_model_size:.2f} MB\")\n",
        "print(f\"Quantized - Accuracy: {quant_acc:.4f}, Loss: {quant_loss:.4f}, Size: {quant_model_size:.2f} MB\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "K_Gvpl1MTeJu"
      },
      "outputs": [],
      "source": [
        "# ---------------------------------------\n",
        "# Quantization Aware Training (QAT)\n",
        "# ---------------------------------------\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import tensorflow_model_optimization as tfmot\n",
        "import tempfile, os\n",
        "\n",
        "float_model= model\n",
        "# Evaluate float model\n",
        "float_loss, float_acc = float_model.evaluate(x_test, y_test, verbose=0)\n",
        "\n",
        "# Save float model and measure size\n",
        "_, float_fp = tempfile.mkstemp('.h5')\n",
        "float_model.save(float_fp)\n",
        "float_size = os.path.getsize(float_fp) / 1e6  # MB\n",
        "\n",
        "# ----------------------------\n",
        "# 4. Prepare QAT model\n",
        "# ----------------------------\n",
        "quantize_model = tfmot.quantization.keras.quantize_model\n",
        "qat_model = quantize_model(float_model)  # apply QAT wrappers\n",
        "\n",
        "qat_model.compile(optimizer='adam',\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "# Fine-tune with QAT for a few epochs\n",
        "qat_model.fit(x_train, y_train, epochs=3, batch_size=128,\n",
        "              validation_split=0.1, verbose=2)\n",
        "\n",
        "# Evaluate QAT (still float inference with fake-quant)\n",
        "qat_loss, qat_acc = qat_model.evaluate(x_test, y_test, verbose=0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "_d8_QzteUCt0"
      },
      "outputs": [],
      "source": [
        "# ----------------------------\n",
        "# 5. Convert both to TFLite\n",
        "# ----------------------------\n",
        "def convert_to_tflite(keras_model, tflite_path):\n",
        "    converter = tf.lite.TFLiteConverter.from_keras_model(keras_model)\n",
        "    converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "    converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
        "    converter.inference_input_type = tf.uint8\n",
        "    converter.inference_output_type = tf.uint8\n",
        "\n",
        "    def representative_data_gen():\n",
        "        for i in range(100):\n",
        "            yield [x_train[i:i+1].astype(np.float32)]\n",
        "\n",
        "    # Always needed for full integer quantization\n",
        "    converter.representative_dataset = representative_data_gen\n",
        "\n",
        "    tflite_model = converter.convert()\n",
        "    with open(tflite_path, 'wb') as f:\n",
        "        f.write(tflite_model)\n",
        "    return tflite_model\n",
        "\n",
        "# float→quantized TFLite\n",
        "float_tflite_path = os.path.join(tempfile.gettempdir(), \"lenet_float.tflite\")\n",
        "_ = convert_to_tflite(float_model, float_tflite_path)\n",
        "float_tflite_size = os.path.getsize(float_tflite_path) / 1e6\n",
        "\n",
        "qat_tflite_path = os.path.join(tempfile.gettempdir(), \"lenet_qat.tflite\")\n",
        "_ = convert_to_tflite(qat_model, qat_tflite_path)\n",
        "qat_tflite_size = os.path.getsize(qat_tflite_path) / 1e6\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "veaC-Al9UHJ5"
      },
      "outputs": [],
      "source": [
        "# ----------------------------\n",
        "# 6. Evaluate TFLite Models\n",
        "# ----------------------------\n",
        "def evaluate_tflite(model_path):\n",
        "    interpreter = tf.lite.Interpreter(model_path=model_path)\n",
        "    interpreter.allocate_tensors()\n",
        "    inp_det = interpreter.get_input_details()[0]\n",
        "    out_det = interpreter.get_output_details()[0]\n",
        "\n",
        "    correct = 0\n",
        "    preds = []\n",
        "    for i in range(len(x_test)):\n",
        "        img = x_test[i:i+1]\n",
        "        # quantize input to uint8\n",
        "        scale, zero_point = inp_det['quantization']\n",
        "        img_q = (img / scale + zero_point).astype(np.uint8)\n",
        "        interpreter.set_tensor(inp_det['index'], img_q)\n",
        "        interpreter.invoke()\n",
        "        out_q = interpreter.get_tensor(out_det['index'])\n",
        "        preds.append(out_q)\n",
        "        if np.argmax(out_q[0]) == y_test[i]:\n",
        "            correct += 1\n",
        "\n",
        "    acc = correct / len(x_test)\n",
        "    # compute loss (dequantize outputs)\n",
        "    preds = tf.constant(np.vstack(preds), dtype=tf.float32)\n",
        "    loss = tf.keras.losses.sparse_categorical_crossentropy(y_test, preds)\n",
        "    return acc, float(tf.reduce_mean(loss).numpy())\n",
        "\n",
        "float_tflite_acc, float_tflite_loss = evaluate_tflite(float_tflite_path)\n",
        "qat_tflite_acc,   qat_tflite_loss   = evaluate_tflite(qat_tflite_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "cnw-tqhuUKFN"
      },
      "outputs": [],
      "source": [
        "# ----------------------------\n",
        "# 7. Print Comparison\n",
        "# ----------------------------\n",
        "print(\"\\nResults Comparison:\")\n",
        "print(f\"FP32 Keras    - Acc: {float_acc:.4f}, Loss: {float_loss:.4f}, Model size: {float_size:.2f} MB\")\n",
        "print(f\"QAT Keras     - Acc: {qat_acc:.4f}, Loss: {qat_loss:.4f}, Model size: {float_size:.2f} MB  (same .h5 size)\")\n",
        "print(f\"FP32 TFLite   - Acc: {float_tflite_acc:.4f}, Loss: {float_tflite_loss:.4f}, Model size: {float_tflite_size:.2f} MB\")\n",
        "print(f\"QAT  TFLite   - Acc: {qat_tflite_acc:.4f}, Loss: {qat_tflite_loss:.4f}, Model size: {qat_tflite_size:.2f} MB\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}